{"nbformat_minor": 1, "cells": [{"source": "# Visual perception from your local camera\n", "cell_type": "markdown", "metadata": {}}, {"source": "## 1- Introduction\n\n<img src=\"http://127.0.0.1:8000/static/remoteAcademy/images/filteredImage.png\" width=\"35%\" height=\"35%\" style=\"float:right;padding:1px\"/>\nIn this exercise we are going to implement a color filter to segment an object in an image provided either by your local camera, a local video file or an external camera controlled by a ROS/ICE plugin. By default, this notebook will get images from your local video device, such as webcams. To resolve this exercise, the student needs to have at least the next knowledge:\n\n- Color spaces (RGB, HSV, etc)\n- Python programming skills\n- Basic understanding of [OpenCV library](http://opencv.org/)", "cell_type": "markdown", "metadata": {}}, {"source": "## 2 - Exercise components\n\n### 2.1 Local Camera\n\nThe video device that your computer includes by default (this is: the one in /dev/video0) will be the main component of this exercise. Ir provides a Class which abstracts a Camera from a local device, and provides the methods to keep it constantly updated, so that we will be able to get images from it.\n\nThis exercise also allows selecting the video source that we want to use. Although it is intended to solve the exercise of the filter through the student's local camera, he/she can also select another video source (video file stored in the local file system or a camera via ROS / ICE) through the configuration file 'color_filter_conf.yml'.\n\n\n![selectablesource](http://127.0.0.1:8000/static/remoteAcademy/images/selectablesource.png \"Selectable Video Source\")\n\n### 2.2 Color Filter component\n\nThis component has been developed specifically to carry out this exercise. This component connects to the video source to receive images from it.\n\nThe student has to modify this component and add code to accomplish the exercise. In particular, it is required to modify the ``execute()`` method.\n\n### 2.3 Printers\n\nThis methods allow to print an image in a Jupyter Notebook for debugging purposes. It will receive processed images from Color Filter to debug our algorithm, or any other image you want to see. ", "cell_type": "markdown", "metadata": {}}, {"source": "## 3 - Exercise initialization\n\nTo start coding, we need to use ``ColorFilter`` class. Given that a ColorFilter class object starts automatically, you will only need to modify its execute() method, and then run your code through its play() method. Once you have coded your solution to the exercise, go to the end of **block 3** and click \"Play Code\". You will see the message ``Color filter is running``, and then your code will be executed.\n\nTo code the execute() method, follow these instructions:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": true}, "outputs": [], "source": "# In case you want to use CameraServer (ROS/ICE), uncomment next lines.\n\n#import subprocess\n#cameraserver = subprocess.Popen((\"cameraserver\", \"cameraserver_conf.cfg\"))"}, {"source": "Once our video source is serving images, we can start coding to segment any object. With that putpose, we recommend you to use objects with plain colors, in such a way that the filter values are easier to adjust. We need to modify the ``execute()`` method from Color Filter component with the logic that implements the filter. This method will be called iteratively about 10 times per second. To understand how it works, we are going to print a message in each iteration:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": true}, "outputs": [], "source": "# Implement execute method\ndef execute(self):\n    print \"Running execute iteration\"\n      \ncf.setExecute(execute)"}, {"source": "Stop printing updating the method with an empty code:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "metadata": {"trusted": true}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Code updated\n"}], "source": "def execute(self):\n\n    input_image = self.camera.getImage()\n    if input_image is not None:\n        self.set_color_image(input_image)  \n        smooth_image = cv2.GaussianBlur(input_image,(5,5),0)\n        HSV_smooth_image = cv2.cvtColor(smooth_image, cv2.COLOR_RGB2HSV)\n        lower_boundary = np.array([110,155,0], dtype = \"uint8\")\n        upper_boundary = np.array([179,255,255], dtype = \"uint8\")\n\n        # PARA UN OBJETO AZUL\n        lower_boundary2 = np.array([109,0,0], dtype = \"uint8\")\n        upper_boundary2 = np.array([128,255,255], dtype = \"uint8\")\n        # -------------------\n\n        mask = cv2.inRange(HSV_smooth_image,lower_boundary,upper_boundary)\n        mask2 = cv2.inRange(HSV_smooth_image,lower_boundary2,upper_boundary2)\n        #self.camera.set_filtered_image(mask)\n        input_image_copy = input_image\n\n        mask_copy2 = np.copy(mask2)\n        im2_2, contours2, hierarchy2 = cv2.findContours(mask_copy2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n        if contours2 != []:\n            contour = sorted(contours2, key = cv2.contourArea, reverse = True)[0] \n            # Ordenamos los contornos por su area (de mayor a menor)\n            x,y,w,h = cv2.boundingRect(contour)\n            rectangle = cv2.rectangle(input_image_copy, (x,y), (x+w,y+h),(255,117,20),2)\n            self.set_filtered_image(rectangle)\n\ncf.setExecute(execute)"}, {"source": "**REMEMBER:** You can use the ``pause()`` method of ColorFilter class to do an \"*Academic Pause*\", so that you are able to pause your algorithm, make some changes in the ``execute()`` method and setting those changes as shown above, and then resume your algorithm execution by running the ``play()`` method:\n\n1.- Pause\n```\ncf.pause()\n```\n\n2.- Change execute() method\n```\ndef execute(self):\n    #make some changes\n      \ncf.setExecute(execute)\n```\n3.- Resume\n```\ncf.play()\n```\n\nOr just use the follwing \"Play Code/Pause Code\" toggle button:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "metadata": {"init_cell": true, "hide_input": true, "trusted": true}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "  Chosen source: local camera (index 0)\n0 is not a valid device index in this machine.\n"}, {"ename": "SystemExit", "evalue": "Please check your camera id (hint: ls /dev)", "traceback": ["An exception has occurred, use %tb to see the full traceback.\n", "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Please check your camera id (hint: ls /dev)\n"], "output_type": "error"}, {"output_type": "stream", "name": "stderr", "text": "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"}], "source": "#! /usr/bin/env python\n\nfrom color_filter import ColorFilter\nfrom color_filter import printImage\nimport ipywidgets as w\nfrom IPython.display import display\nfrom IPython.display import clear_output\n\nimport numpy as np\nimport cv2\n%matplotlib inline\n\n# Init color filter\ncf = ColorFilter()\n\ndef playcode():\n    cf.play()\n    \ndef pausecode():\n    cf.pause()\n    \nplaypausebutton = w.ToggleButton(description='Play Code', button_style='success', icon='check', layout=w.Layout(margin='1% 0 0 30%'))\n\ndef onclick(change):\n    if change['new']:\n        playpausebutton.description = \"Pause Code\"\n        playpausebutton.button_style ='danger'\n        playpausebutton.icon='stop'\n        playcode()\n    else: \n        playpausebutton.description = \"Play Code\"\n        playpausebutton.button_style ='success'\n        playpausebutton.icon='check'\n        pausecode()\n\nplaypausebutton.observe(onclick, 'value')\n\ntoggle = w.ToggleButton(description='Enable Visualization', layout=w.Layout(margin='1% 0 0 1%'))\n\ndef on_click(change):\n    if change['new']:\n        toggle.description = \"Disable Visualization\"\n        cf.algorithm.visualizationEnabled = True\n    else: \n        toggle.description = \"Enable Visualization\"\n        cf.algorithm.visualizationEnabled = False\n        clear_output()\n        displaybuttons()\n\ntoggle.observe(on_click, 'value')\n\ndef displaybuttons(): \n    display(w.HBox((playpausebutton, toggle)))\ndisplaybuttons()\ncf.algorithm.displaybuttons = displaybuttons"}, {"source": "## 4 - Image manipulation\n\nColor filter receives images from your local camera in principle. To obtain these images you can run this code inside the``execute()`` method:\n\n```\nimage_input = self.camera.getImage()\n```\n\nTo debug our code and show the output, there are two images that can be visualized:\n\n- We can visualize an RGB image (three channels), employed to show the images received from the simulator or manipulate them. You can set this images with this code:\n\n```\nself.set_color_image(image_three_channels)\n```\n\n- We can visualize a gray image (one channels), employed to show the color filter result:\n\n```\nself.set_filtered_image(image_one_channels)\n```\n\nYou can recover these images afterwards with these commands:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": true}, "outputs": [], "source": "# RGB image\nimageRGB = cf.get_color_image()\n\n# Filtered image\nfilteredGray = cf.get_filtered_image()"}, {"source": "To print any of these images in this Notebook, just recover it (get_color_image, get_filtered_image or getImage methd shown above), and then call the ``printImage()`` method, i.e:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": true}, "outputs": [], "source": "# Example: print the image provided from the camera\nimageCamera = cf.camera.getImage()\nprintImage(imageCamera)"}, {"source": "**NOTE:** Each 3 seconds, the ColorFilter Class will automatically try to print a filtered image (it will only print it if you have previously set a filtered image with the ``set_filtered_image(img)`` method as shown above.", "cell_type": "markdown", "metadata": {}}, {"source": "You are also allowed to press the 'Show 10 frames' button below to print camera's images every two seconds:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"init_cell": true, "hide_input": true, "trusted": true}, "outputs": [], "source": "from color_filter import printVideo\n\ncf.show = False\nframes = 10\ndef showCamera(ev):\n    for x in range(0, frames):\n        im = cf.camera.getImage()\n        cf.algorithm.set_color_image(im)\n        # Show color image\n        imageCamera = cf.get_color_image()\n        #filteredImage = cf.get_filtered_image()\n        printVideo(imageCamera)\n        #printVideo(filteredImage) \n        clear_output()\n    button = w.Button(button_style='info',description=\"Show \" + str(frames) + \" frames\")\n    button.on_click(showCamera)\n    display(button)\n    \nbutton = w.Button(button_style='info',description=\"Show \" + str(frames) + \" frames\")\nbutton.on_click(showCamera)\ndisplay(button)"}, {"source": "## 5 - Programming a color filter segmentation\n\n\nTo accomplish this exercise the student has to implement a color filter that segments a box and detects its position inside the image.\n\nThus, given an input image like this image:\n\n![Input image](http://127.0.0.1:8000/static/remoteAcademy/images/inputImage.png \"Input image\")\n\nThe expected output would be similar to this image:\n\n![Output image](http://127.0.0.1:8000/static/remoteAcademy/images/filteredImage.png \"Output image\")\n\nTo obtain this result, the proposed pipeline is:\n\n1. Smooth image\n2. RGB to HSV conversion\n3. Color filter\n4. Rectangle approximation\n5. Object detection\n\nThis steps are detailed in the next sections and can be easily conducted using [OpenCV library](https://opencv.org/ \"OpenCV\")", "cell_type": "markdown", "metadata": {}}, {"source": "### 5.1 - Smooth image\n\nImage smoothing is useful to remove noise or imperfections in image. For this exercise, we recommend to use a *Gaussian Filter*, that can be found in OpenCV library as [GaussianBlur](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=gaussianblur#gaussianblur). The expected result of this filter from the input image shown in previous section is this:\n\n![Smoothed image](http://127.0.0.1:8000/static/remoteAcademy/images/smoothImage.png \"Smoothed image\")", "cell_type": "markdown", "metadata": {}}, {"source": "### 5.2 - RGB to HSV conversion\n\nThe images received from your camera have an RGB color space. This color space is useful to represent digital images but it is also very sensitive to light changes. Therefore, the next step is to convert our RGB image into a HSV image. We recommend to use the [cvtColor](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor) function from OpenCV.\n\nIf we print this image, the expected result will be similar to this image:\n\n![HSV image](http://127.0.0.1:8000/static/remoteAcademy/images/hsvImage.png \"HSV image\")", "cell_type": "markdown", "metadata": {}}, {"source": "### 5.3 - Color filter\n\nNow we can apply our color filter to the HSV image. The OpenCV function [inRange](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?highlight=inrange#inrange) can help us to make this color filter.\n\nThis function receives two arrays, the first one sets the lower HSV values of the filter, and the second one the upper values. For the first parameter (H), the expected values are in range [0, 180], whereas for S and V the values are in range [0, 255]. Thus, a filter where all pixels would be validated would have this appearance:\n\n```\nlower_values = np.array([0,0,0], dtype=np.uint8)\nupper_values = np.array([180,255,255], dtype=np.uint8)\n```\n\nNote: To represent arrays we employ the [numpy library](http://www.numpy.org/)\n\nOnce the maximum and minimum values for each HSV parameters have been properly set, the thresholded image (with one channel) has to be similar to this one:\n\n![Thresholded image](http://127.0.0.1:8000/static/remoteAcademy/images/thresholdImage.png \"Thresholded image\")", "cell_type": "markdown", "metadata": {}}, {"source": "### 5.4 - Rectangle approximation\n\nTrying to find a white object inside a black background is easier than trying to find a colored one inside a changing background. Therefore, from now on, we will use the thresholded image calculated in the previous step.\n\nOne option to detect the box could be detecting the object contour with [findContours](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#findcontours) function. This function modifies the input image, so we recommend to create a copy before using it with the [numpy copy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.copy.html) function.\n\nFindContours returns a list of points that defines the object contour. This points can be approximated to polygons using one of the next OpenCV functions: [approxPolyDP](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#approxpolydp) or [boundingRect](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#boundingrect). You can also draw the obtained rectangle with [rectangle](https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html?highlight=rectangle#rectangle) function.", "cell_type": "markdown", "metadata": {}}, {"source": "### 5.5 - Object detection\n\nSince color filtering parameters are not easy to adjust (even in simulated environments), there may be several image regions with rectangles calculated in previous step. One rectangle will belong to the box we are trying to detect, where as the rest will be noisy regions.\n\nIn this case, we recommend to filter the calculated rectangles to show only the one belonging to the object you want to segment. You can pick up the proper rectangle setting up some restrictions, like rectangle size or shape deppending on the size of your selected object.\n\nThe final result will be the output image we show at the beginning of this section.\n\n![Output image](http://127.0.0.1:8000/static/remoteAcademy/images/filteredImage.png \"Output image\")", "cell_type": "markdown", "metadata": {}}, {"source": "## 6 - Algorithm skeleton\n\nWe provide an skeleton where you can code your color filtering following the previous steps:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": true}, "outputs": [], "source": "def execute(self):\n      \n    # Get image\n    input_image = self.camera.getImage()\n    if input_image is None:\n        print \"Can't get images from camera, is your local camera working?\"\n        return\n    \n    if input_image.any(): \n        output_img = np.copy(input_image)\n        \n        # Smooth image\n        # Add your code here\n        \n        # RGB to HSV conversion\n        # Add your code here\n        \n        # Color filter\n        # Add your code here\n        \n        # Rectangle approximation\n        # Add your code here\n        \n        # Box detection\n        # Add your code here\n\n        # Save images\n        self.set_color_image(output_img)\n        #self.set_filtered_image(thresold_img)\n\ncf.setExecute(execute)"}, {"source": "You can see saved images running this code:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {"scrolled": true, "trusted": true}, "outputs": [], "source": "# Show color image\nimageCamera = cf.get_color_image()\nprintImage(imageCamera)"}, {"execution_count": null, "cell_type": "code", "metadata": {"scrolled": true, "trusted": true}, "outputs": [], "source": "# Show filtered image\nimageCamera = cf.get_filtered_image()\nprintImage(imageCamera)"}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "2.7.12", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}, "celltoolbar": "Initialization Cell"}, "nbformat": 4}